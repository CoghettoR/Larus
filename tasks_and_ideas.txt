fof(initial_model, axiom, (r(x) | r(y)) ). 
fof(disjingoal,conjecture, r(y) | r(x)).

TODO:

 3. Generate "excluded middle" axioms for Coq, when used/needed
 4. Explain the encoding in the paper  
 5. Make smt-uflia and smt-ufbf engines
 6. Do not use always the same file names for temporary files like prove.urs etc...
    to be able to run instances of the provers in parallel.
 8. Handle nInst in ursa/smt in EQ/ExcludedMiddle axiom (currently they are not instantiate).
10. Julien: For equality, I had hope that with a native encoding we can have something more 
    efficient than the version which adds the axioms.
    Donâ€™t you want to run run a full bench with/without native before dropping the support ?
11. Julien: Maybe we could use this idea also using some meta-theorems or heuristics: 
    if the goal has some given form then some of the hypotheses should be used:
    (1) "use necessarily all the given axioms"
    (2) "use necessarily this axioms" (can be repeated several times)

12. Test interesting to test Isabelle and Coq hammer.


DONE:

 1. Make looking for a shortest proof/any proof correct
 2. Handle native equality (update corpus, parser, added axioms)
 7. Remove hard coded old benches in the .cpp files.
 9. Differentiate between "n" prefix for negation and "n" prefix for URSA; use longer prefix for negated predicates symbols
12. Julien: names with underscore are assumed to be internal auxiliary predicates (introduced by CL2 normalization)
    I think we should replace it with something less common , like starting with three underscores.


*******************************************************************************************************************

BUGS:

1. 23.03.2020. Julien
CLprover/Stl prover seems to be stuck with some examples
coherent-logic-benches
I think it does not obey to the timeout command.
[Many changes afterwards, maybe this is obsolete bug.]

2. 24.03.2020. Julien
the file:
tptp-problems/coherent-logic-benches/anl.in.p
produces a wrong proof:
It wrongly assumes that the variables in the first axiom (initial_model) are universally quantified, but they are constants.
In tptp constant starts with a lowercase and variables with an uppercase.
assert (dom_dom_0_dom_0_rr_0_ss_0 a a a) by applying (initial_model).
[Many changes afterwards, maybe this is obsolete bug.]

3. 25.03.2020. 
Using z3 i get a lot of errors like:
Proving theorem: lemma_Euclid4:(! [A,B,C,Xa,Xb,Xc] : ((per(A,B,C) & per(Xa,Xb,Xc)) => ((congA(A,B,C,Xa,Xb,Xc)))))
Trying proof length 1;
Trying proof length 2;
Trying proof length 4;
Trying proof length 8;The model file is empty !
Is it normal failure ?
[Many changes afterwards, maybe this is obsolete bug.]

4. Julien: 06.04.2020.
Proofs only of size 32:
Benches: Col trans 100
Time given: 30
Engine: SMT-BV
0031 it fails to prove using proof size 32 can be proved using
proof size 8!
Number 0035 seems to be problematic as well. 

RESOLVED:

5. Predrag: 07.04.2020.
// FIXME: BV complains about adding negative number
       snNegIntroCheck += smt_ite(appeq(app("nAxiomApplied", nProofStep), eQEDbyNegIntro), -1, 0);
- Adding -1 replaced by difference of two sums



*******************************************************************************************************************

IDEAS:

1. Julien: Here are some ideas of potential additional constraints to reduce the search space:
- all axioms should be used in the proof
- the same fact should not be derived twice in the same branch

2. Julien: I noticed that we can optimize the encoding:
the formula of the form A & B & C & D are encoded using
P -> A
P -> B
P -> C
P -> D
When there is no assumption I think we can just split the facts:
A
B
C
D.

3. Julien: The readable proof we have a cut-free (we do not introduce lemma),  
I wondering if we can really generate readable proof which provide explaination 
without introducing lemmas.

4. Julien: It seems that for some problems the function which maps n to the time to 
find a proof or fail to find a proof of n is not increasing in n!  
larger value of n can sometimes give much smaller computing time.
It would be hard to implement, but maybe on our several cores computer 
we could run in parallel size 8, 16, 32 and take the first answer ? or 
another solution is to give this problem to the solver.

Predrag: This is absolutely sensible idea. But I see the following problems:
(1) First and most important :) I don't have experience with 
multicore programming - maybe it is not that difficult;
(2) Even if I make it work on my computer, it might not work on 
your Mac or StarExec, so we could have other troubles;
(3) Parallelization of this kind is rather orthogonal to our
current attempts: looking for suitable encodings etc. More
cores or more computers is something that can be always 
addressed later.

5 Julien: to deal with symmetry we can make an experiment by imposing the order of the point in Col predicates, deriving Col X Y Z we can add a constraint that X <= Y <= Z.

6. Julien: Idea for tree traversal for annotating Nesting

7. Julien: I just realized that the example non_nested_case_split produces proofs only with 
nested case split. It is not a bug, it is just that CL does not allow "subproofs". 
I would have expected the following proof (not the step with just an assert). It is just a 
thought. I am not sure we should implement that.

Theorem nonnestedcasesplit : forall Z : MyT, r Z -> g1 Z /\ g2 Z.
Proof.
intros ca.
intros.
assert(g1 ca).
 {
  assert (p ca \/ q ca) by applying (ax1 ca).
  by cases on (p ca \/ q ca).
  - assert (g1 ca) by applying (ax2 ca).
    conclude.
  - assert (g1 ca) by applying (ax3 ca).
    conclude.
}
assert(g2 ca).
 {
  assert (p2 ca \/ q2 ca) by applying (ax4 ca).
  by cases on (p2 ca \/ q2 ca).
  - assert (g2 ca) by applying (ax5 ca).
   conclude.
  - assert (g2 ca) by applying (ax6 ca).
   conclude.
}
conclude.
Qed.

8. Julien: Maybe we could implement something similar to RETE algorithm in the encoding:
 if two rules share some assumptions, we could share some part of the matching ?

9. Predrag: Namely, there are some theorems proved
    easily by stl and not by ursa and vice versa. Why?
    For instance, if there is an axiom "dom(a) & dom(b)", the stl
    engine will quickly apply it, while the ursa engine would consider
    all possible axioms for all possible proof steps. Thanks to this,
    stl proves some theorems, and ursa does not. We have to exploit these things. 

10. Julien:
> Let's assume that we have natural language proof in latex and we want to turn it into a formal proof. The structure of such a proof is hard to  reconstruct automatically, it is hard to formalize each sentence in the proof. But it may help our prover to detect just a few things in the proofs and to try to reconstruct the proof using these pieces of information.
> Maybe we could help the CLprover/SAT/SMT by saying that some proof steps is using (perp_bisect_cong2 G A' B C)
> but we do not have to provide the precise information that it is in a subgoal to prove Cong B C C G.
...
> So the approach would be a little bit different that  just cutting the natural proof in small pieces in order to try to get a formal proof. Here we would help the system  by giving some information. I think it would be closer to what a human does when he formalizes a natural language proof: you have hints that you should use some proofs steps. But usually the natural language proof forgets some special cases. So if you try to prove automatically that one step can be derived from the previous it will fail because sometimes some assumptions are missing. For example, in Euclid proof, often only the proof in the general case is given.





